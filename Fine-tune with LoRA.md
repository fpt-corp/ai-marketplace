# Supervised Fine-Tuning for Text (SFT)

This guide focuses on using **supervised fine-tuning** (SFT) to fine-tune and deploy a model with **on-demand** and **serverless hosting**.

---

## üìå List of Supported Models

We currently support fine-tuning models with the following architectures:

| Model (Resource)                              | Suggested Learning Rate (small ‚Üí med) | Suggested Epochs |
|-----------------------------------------------|---------------------------------------------|------------------------------|
| **Qwen-3 / Qwen3-4B-Instruct** (template 1 GPU) | small: `1e-5 ‚Üí 5e-5`<br>med: `5e-5 ‚Üí 1e-4` | small: 1‚Äì3<br>med: 3‚Äì5   |
| **google/gemma-3-27b-it** (template 2 GPUs)   | small: `1e-5 ‚Üí 5e-5`<br>med: `5e-5 ‚Üí 1e-4` | 3 (start)   |
| **meta-llama/Llama-3.3-70B** (template 4 GPUs) | small: `1e-5 ‚Üí 2e-5`<br>med: `2e-5 ‚Üí 1e-4` | 3 (start)   |

---

## üìÇ Dataset Format

| Dataset Type   | Link to Sample                                                                 | Note                                                                                      |
|----------------|--------------------------------------------------------------------------------|-------------------------------------------------------------------------------------------|
| **Alpaca**     | [Alpaca Sample](https://github.com/fpt-corp/ai-studio-samples/tree/main/sample-datasets/alpaca) | D·ªÖ chu·∫©n b·ªã, ph√π h·ª£p v·ªõi c√°c use case instruction tuning c∆° b·∫£n (summarization, QA, rewriting). |
| **ShareGPT**   | [ShareGPT Sample](https://github.com/fpt-corp/ai-studio-samples/tree/main/sample-datasets/sharegpt) | Ph√π h·ª£p khi ng∆∞·ªùi d√πng mu·ªën fine-tune chatbot c√≥ kh·∫£ nƒÉng h·ªôi tho·∫°i nhi·ªÅu v√≤ng.            |
| **ShareGPT_Image** | [ShareGPT_Image Sample](https://github.com/fpt-corp/ai-studio-samples/tree/main/sample-datasets/sharegpt-image) | D√†nh cho nh√≥m user n√¢ng cao, l√†m v·ªÅ AI ƒëa ph∆∞∆°ng ti·ªán.                                   |

---

## üí° What is Training Data?

In the fine-tuning process, **data** refers to a curated set of example inputs and outputs used to retrain a pre-trained AI model.  
This data teaches the model to adapt its behavior to suit your **specific domain, task, or tone of voice**.

## **1. Alpaca**

**Alpaca** uses a very simple structure to fine-tune the model with Instruction-following format with input, output pairs for **supervised fine-tuning** tasks. The basic structure includes:

- **Instruction**: A string containing the specific task or request that the model needs to perform.
- **Input**: A string containing the information that the model needs to process in order to carry out the task.
- **Output**: A string representing the result the model should return, generated from processing the instruction and input.

**Detailed Structure:** 

[
   {
      ‚Äúinstruction‚Äù: ‚Äústring‚Äù,
      ‚Äúinput‚Äù: ‚Äústring‚Äù,
      ‚Äúoutput‚Äù ‚Äústring‚Äù
  }
]

**Examples**:

```json
[
    {
        "instruction": "In this task, you are given Wikipedia articles on a range of topics as passages and a question from the passage. We ask you to answer the question by classifying the answer as 0 (False) or 1 (True)\n\nNow complete the following instance -\nInput: Passage: Missouri River -- Tonnage of goods shipped by barges on the Missouri River has seen a serious decline from the 1960s to the present. In the 1960s, the USACE predicted an increase to 12 million short tons (11 Mt) per year by 2000, but instead the opposite has happened. The amount of goods plunged from 3.3 million short tons (3.0 Mt) in 1977 to just 1.3 million short tons (1.2 Mt) in 2000. One of the largest drops has been in agricultural products, especially wheat. Part of the reason is that irrigated land along the Missouri has only been developed to a fraction of its potential. In 2006, barges on the Missouri hauled only 200,000 short tons (180,000 t) of products which is equal to the amount of daily freight traffic on the Mississippi.\nQuestion: is there barge traffic on the missouri river\nOutput:",
        "input": "",
        "output": "1"
    },
    {
        "instruction": "CARA√èBES Communaut√© des Cara√Øbes (CARICOM) Aper√ßu Les 15 membres de la Communaut√© des Cara√Øbes (CARICOM) sont Antigua et Barbuda, les Bahamas, la Barbade, le Belize, la R√©publique dominicaine, la Grenade, la Guyane, Ha√Øti, la Jama√Øque, Saint-Kitts-et-Nevis, Sainte-Lucie, Saint Vincent et les Grenadines, le Suriname, Trinit√©-et-Tobago, ainsi que Montserrat (sous la d√©pendance du Royaume-Uni).\n\nWhich language is this?",
        "input": "",
        "output": "French"
    }
]
```
**Samples**: https://github.com/fpt-corp/ai-studio-samples/tree/main/sample-datasets/alpaca

## **2. ShareGPT**

**a. Trainer = SFT**

**ShareGPT** is designed to represent multi-turn conversations (back-and-forth chats) between a user and an AI assistant. It is commonly used when training or fine-tuning models for dialogue systems or chatbots that need to handle contextual conversation over multiple turns.

Each data sample consists of a `conversations` array, where each turn in the chat includes:

- **from**: Who is speaking ‚Äî usually `"human"` or `"system"`.
- **value**: The actual message text from that speaker.

**Detailed Structure:** 

[
   {
      ‚Äúconversations‚Äù: [
         {
            ‚Äúfrom‚Äù: ‚Äústring‚Äù,
            ‚Äúvalue‚Äù: ‚Äústring‚Äù
         }
      ]
   }
]

**Examples**:

```json
[
    {
        "conversations": [
            {
                "from": "system",
                "value": "You are Qwen, created by Alibaba Cloud. You are a helpful assistant."
            },
            {
                "from": "human",
                "value": "Select the latest conversation state of the provided conversation history. Response only with the conversation state index.\n\n# Context\n- H√¥m nay: Th·ª© t∆∞, 19/02\n- H·ªç t√™n kh√°ch h√†ng: L√ä HO√ÄNG LOAN\n- S·∫£n ph·∫©m vay: ƒêi·ªán tho·∫°i Samsung\n- S·ªë ti·ªÅn c·∫ßn thanh to√°n k·ª≥ n√†y: 1515000\n- Ng√†y ƒë·∫øn h·∫°n thanh to√°n k·ª≥ n√†y: 16/02\n- S·ªë ng√†y ƒë√£ tr·ªÖ h·∫°n thanh to√°n: 3\n- H·∫°n thanh to√°n cu·ªëi: 21/02\n\n# Conversation history\nT·ªïng ƒë√†i vi√™n: D·∫° c√≥ ph·∫£i Anh LOAN ƒëang nghe m√°y kh√¥ng ·∫°?\nNg∆∞·ªùi nh·∫≠n cu·ªôc g·ªçi: c√≥ g√¨ kh√¥ng em\n\n# Conversation states\n1) X√°c nh·∫≠n danh t√≠nh c·ªßa m√¨nh l√† kh√°ch h√†ng - V√≠ d·ª•: \"·ª´ ai ƒë·∫•y\", \"ph·∫£i ch·ªã\", \"ƒë√∫ng r·ªìi ai g·ªçi th·∫ø\", \"·ªù v√¢ng\", \"d·∫° v√¢ng\", \"Anh LOAN ƒë√¢y\", \"sao th·∫ø\", \"m√¨nh nghe ·∫°\", \"c√≥ chuy·ªán g√¨\", \"n√≥i ƒëi\"\n2) H·ªèi danh t√≠nh c·ªßa t·ªïng ƒë√†i vi√™n - V√≠ d·ª•: \"ai ƒë·∫•y\", \"b·∫°n t√™n g√¨\", \"b·∫°n l√† ai\", \"c√¥ng ty g√¨\", \"l·ª´a ƒë·∫£o √†\"\n3) X√°c nh·∫≠n l√† ng∆∞·ªùi th√¢n (nh∆∞ √¥ng, b√†, b·ªë, m·∫π, c√¥, d√¨, ch√∫, b√°c, anh, ch·ªã, em, v·ª£, con) c·ªßa kh√°ch h√†ng ho·∫∑c c√≥ quen bi·∫øt kh√°ch h√†ng - V√≠ d·ª•: \"anh l√† anh n√≥\", \"m√¨nh l√† ch·ªã c·ªßa LOAN\", \"b√°c l√† m·∫π n√≥ nghe m√°y h·ªô n√≥ ƒë√¢y\", \"c√¥ l√† d√¨ n√≥\", \"em l√† ng∆∞·ªùi nh√† c·ªßa Anh LOAN\", \"b·∫°n ·∫•y ra ngo√†i r·ªìi m√¨nh l√† b·∫°n c·ªßa b·∫°n ·∫•y\", \"√† Anh l√†m c√πng c∆° quan v·ªõi n√≥\", \"m√¨nh l√† b·∫°n n√≥\", \"quen bi·∫øt qua th√¥i\"\n4) Th√¥ng b√°o kh√¥ng quen bi·∫øt kh√°ch h√†ng ho·∫∑c th√¥ng b√°o nh·∫ßm s·ªë / nh·∫ßm ng∆∞·ªùi ho·∫∑c th√¥ng b√°o kh√°ch h√†ng ƒëi v·∫Øng / ch·ªâ nghe m√°y h·ªô v√† kh√¥ng cung c·∫•p th√¥ng tin v·ªÅ m·ªëi quan h·ªá v·ªõi kh√°ch h√†ng - V√≠ d·ª•: \"c√≥ quen bi·∫øt g√¨ ƒë√¢u\", \"m√¨nh kh√¥ng bi·∫øt b·∫°n ƒë·∫•y\", \"·ªßa s·ªë n√†y c·ªßa t√¥i m√† c√≥ bi·∫øt ƒë·∫•y l√† ai ƒë√¢u\", \"t√¥i nghe h·ªô b·∫°n ·∫•y ra ngo√†i r·ªìi\", \"kh√¥ng nh·∫ßm r·ªìi em ∆°i\", \"LOAN n√†o nh·ªâ\", \"LOAN √° kh√¥ng ph·∫£i r·ªìi\", \"ai c∆°\"\n5) ƒê·ªìng √Ω thanh to√°n chung chung ho·∫∑c th√¥ng b√°o th·ªùi ƒëi·ªÉm ho·∫∑c s·ªë ti·ªÅn s·∫Ω thanh to√°n - V√≠ d·ª•: \"√† ·ªù\", \"ƒë√∫ng r·ªìi\", \"bi·∫øt r·ªìi nh√©\", \"l√°t n·ªØa nh√©\", \"t√Ω n·ªØa gi·∫£ nh√©\", \"mai Anh ƒë√≥ng\", \"ƒë·ªÉ t√¥i s·∫Øp x·∫øp\", \"ƒë·ªÉ h·ªèi nh·ªù ng∆∞·ªùi nh√† xem sao\", \"gi·ªù ch∆∞a c√≥ nh∆∞ng mai s·∫Ω tr·∫£\", \"ng√†y kia tr·∫£ ƒë∆∞·ª£c kh√¥ng nh·ªâ\"\n6) ƒê·∫∑t c√¢u h·ªèi ho·∫∑c th·∫Øc m·∫Øc v·ªÅ kho·∫£n n·ª£, s·ªë hotline, ph∆∞∆°ng th·ª©c thanh to√°n, ng√†y th√°ng - V√≠ d·ª•: \"t√¥i vay s·∫£n ph·∫©m n√†o ·∫•y nh·ªâ\", \"Anh c·∫ßn tr·∫£ bao nhi√™u ti·ªÅn ·∫•y nh·ªâ\", \"Anh ch∆∞a bi·∫øt c·∫•ch thanh to√°n nh∆∞ th·∫ø n√†o ·∫•y\", \"h·ª£p ƒë·ªìng c·ªßa t√¥i c√≤n bao nhi√™u k·ª≥ n·ªØa\", \"∆° h·∫°n thanh to√°n l√† ng√†y m√πng s√°u h√†ng th√°ng m√† nh·ªâ\", \"sao l·∫°i nhi·ªÅu ti·ªÅn th·∫ø nh·ªâ\", \"sao th√°ng n√†y c·∫ßn ƒë√≥ng nhi·ªÅu ti·ªÅn h∆°n th√°ng tr∆∞·ªõc\", \"l√£i su·∫•t qu√° h·∫°n l√† bao nhi√™u h·∫£ em\", \"Anh ƒë√≥ng lu√¥n m·∫•y k·ª≥ c√≤n l·∫°i ƒë∆∞·ª£c kh√¥ng\", \"h√¥m nay ng√†y m·∫•y nh·ªâ\", \"s·ªë ƒëi·ªán tho·∫°i ph·∫£n √°nh l√† s·ªë m·∫•y\", \"kh√¥ng bi·∫øt ƒë√≥ng ·ªü c·ª≠a h√†ng n√†o\"\n7) B√°o b·∫≠n ho·∫∑c ƒëang kh√¥ng ti·ªán nghe m√°y ho·∫∑c h·∫πn g·ªçi l·∫°i sau - V√≠ d·ª•: \"Anh ƒëang b·∫≠n nh√©\", \"t√¥i ƒëang ƒëi l√†m b·∫°n ∆°i\", \"gi·ªù kh√¥ng ti·ªán l·∫Øm g·ªçi l·∫°i sau ƒëi\", \"t√¥i ƒëang ngo√†i ƒë∆∞·ªùng g·ªçi l·∫°i sau nh√©\"\n8) Ph√†n n√†n ho·∫∑c khi·∫øu n·∫°i do b·ªã g·ªçi nhi·ªÅu - V√≠ d·ª•: \"b√™n em g·ªçi nhi·ªÅu th·∫ø\", \"sao m·ªôt ng√†y g·ªçi ch·ª•c cu·ªôc th·∫ø h·∫£ em\", \"ƒë·ª´ng c√≥ g·ªçi n·ªØa m·ªát l·∫Øm r·ªìi\"\n9) Kh√¥ng nghe r√µ ho·∫∑c y√™u c·∫ßu nh·∫Øc l·∫°i th√¥ng tin - V√≠ d·ª•: \"alo em n√≥i g√¨ th·∫ø\", \"Anh ch∆∞a nghe ƒë∆∞·ª£c em ∆°i\", \"·ª´ c√°i g√¨ ·∫•y nh·ªâ\", \"b·∫°n n√≥i l·∫°i gi√∫p m√¨nh v·ªõi\", \"·ªìn qu√° m√¨nh kh√¥ng nghe ƒë∆∞·ª£c ·∫•y\", \"kh√¥ng n√≥i g√¨ √†\"\n10) Th√¥ng b√°o kh√°ch h√†ng ƒë√£ qua ƒë·ªùi - V√≠ d·ª•: \"b·∫°n ·∫•y b·ªã t·∫°i n·∫°n m·ªõi m·∫•t r·ªìi\", \"n√≥ qua ƒë·ªùi r·ªìi em ·∫°\", \"Anh LOAN ch·∫øt r·ªìi b·∫°n ∆°i\"\n11) Mu·ªën g·∫∑p t·ªïng ƒë√†i vi√™n - V√≠ d·ª•: \"cho t√¥i n√≥i chuy·ªán v·ªõi t·ªïng ƒë√†i b√™n b·∫°n n√†o\", \"Anh mu·ªën g·∫∑p t·ªïng ƒë√†i vi√™n\", \"chuy·ªÉn m√°y cho t·ªïng ƒë√†i x·ª≠ l√Ω ƒë∆∞·ª£c kh√¥ng\"\n12) Tr·∫£ l·ªùi sai tr·ªçng t√¢m c·ªßa c√¢u h·ªèi tr∆∞·ªõc ƒë√≥ ho·∫∑c cung c·∫•p th√¥ng tin ch∆∞a r√µ r√†ng ho·∫∑c c·∫ßn x√°c nh·∫≠n l·∫°i th√¥ng tin ho·∫∑c ƒë·∫∑t y√™u c·∫ßu ngo√†i ph·∫°m vi h·ªó tr·ª£\n\n# Answer:"
            }
        ]
    }
]
[
    {
        "conversations": [
            {
                "from": "human",
                "value": "Summarize the main ideas of Jeff Walker's Product Launch Formula into bullet points as it pertains to a growth marketing agency implementing these strategies and tactics for their clients..."
            },
            {
                "from": "gpt",
                "value": "Here are the main ideas of Jeff Walker's Product Launch Formula that can be applied by a growth marketing agency for their clients:\n\n1. Identify the target audience and their needs: Understand the ideal customer for the product or service, and create a messaging that resonates with them.\n2. Pre-launch: Build anticipation and excitement for the launch by creating buzz, gathering testimonials and case studies, and using social media to create awareness.\n3. Launch: Use a well-crafted launch sequence to maximize sales and conversions. This can include offering bonuses, creating scarcity, and using a deadline to create urgency.\n4. Post-launch: Follow up with customers, gather feedback, and continue to provide value to keep them engaged and loyal.\n5. Create a product suite: Once the initial product is successful, expand the offering by creating additional products or services that address other needs of the same audience.\n6. Continual optimization: Continually monitor and optimize the launch process and product suite to improve results.\n7. Build a community: Use the launch process to build a community of customers who are passionate about the product and can help spread the word.\n8. Use automation: Use technology and automation to streamline the launch process and improve efficiency."
            }
        ]
    }
]
```

**Samples:** https://github.com/fpt-corp/ai-studio-samples/tree/main/sample-datasets/sharegpt

## **4. ShareGPT_Image**

**ShareGPT_Image** is an extension of the ShareGPT multi-turn chat format, designed specifically for multi-modal training ‚Äî that is, training models that handle both text and images in conversations.

It‚Äôs used in fine-tuning vision-language models (VLMs), which need to process images alongside natural language.

The structure includes:

- A list of **chat turns** under `"message"` (same as ShareGPT).
- A field called `"image"` or `"image_path"` that points to the image used in the conversation (using format png, jpg, jpeg)

### Note

- **Must include the `image` token** in the chat content where an image should appear.
- If there are **multiple images**:
    - Image paths must be defined in an **`images` array**.
    - The **positions of the images** in the chat flow are indicated by the **`image` tokens**
    - The **number of `image` tokens** in the chat must **match the number of items in the `images` array**.
    - Images will be **mapped in order of appearance**, with each `image` token replaced by the corresponding image from the `images` array.
![file](https://fptcloud.com/wp-content/uploads/2025/06/image-1749034071455.42.01.png)

**Detailed Structures:**

[
   {
      ‚Äúmessage‚Äù: [
         {
            ‚Äúrole‚Äù: ‚Äústring‚Äù, ‚Äúcontent‚Äù: ‚Äú<image>string‚Äù
         }
      ],
      ‚Äúimages‚Äù: [
         ‚Äúimages/0.jpg‚Äù
      ]
   }
]

**Examples:**

```json
[
    {
        "messages": [
            {
                "role": "user",
                "content": "<image>How many baseball players are visible in the image?"
            },
            {
                "role": "assistant",
                "content": "There are three baseball players visible in the image."
            }
        ],
        "images": [
            "images/0.jpg"
        ]
    },
    {
        "messages": [
            {
                "role": "user",
                "content": "What is the man wearing in the image?<image>"
            },
            {
                "role": "assistant",
                "content": "The man in the image is wearing chaps, a cowboy hat, and is dressed like a cowboy."
            }
        ],
        "images": [
            "images/1.jpg"
        ]
    },
    {
        "messages": [
            {
                "role": "user",
                "content": "<image>Explain the visual content of the image in great detail."
            },
            {
                "role": "assistant",
                "content": "The image presents a view of a hotel room, showing both the bathroom and bedroom areas. In the bathroom, there is a white sink under a mirror, accompanied by several bottles placed on the counter, and two cups nearby. \n\nLooking through a doorway into the bedroom area, a large bed can be seen dominating the space. A chair is also visible within the room, situated near the foot of the bed. The hair drier is located in the foreground, implying that it likely belongs to the bathroom area as well. The arrangement of the objects and the furniture suggests a comfortable and well-equipped hotel room."
            }
        ],
        "images": [
            "images/2.jpg"
        ]
    }
]
```

**Samples**: [https://github.com/fpt-corp/ai-studio-samples/tree/main/sample-datasets/sharegpt-image](https://github.com/fpt-corp/ai-studio-samples/tree/main/sample-datasets/sharegpt-image)

## 2. Training and Validation Data

- **Training data (required):** the main dataset used for model training.  
- **Validation data (recommended):** used to evaluate model quality during training.  

### 2.1. Data Split Rules
- **Train/Validation split:** 80% / 20%.  
- **Small dataset (<2,000 samples):** you may use the entire dataset for training, but quality will be harder to verify.  
- **Large dataset (>10,000 samples):** always prepare a separate validation set.  

---


## 3. Dataset Validation Rules

In addition to checking file format (CSV, JSON, JSONL, Parquet, ZIP), the system should also validate the dataset content before fine-tuning.  


### 3.1. Basic Validation (Format-level)
- File size must not exceed **100MB**.  
- Must be in a supported format.  
- Training set must contain at least **1,000 samples**.  


### 3.2. Content Validation (Content-level)
**Structure:**  
- Each record must contain **2 fields: `prompt` and `completion`**.  
- Records with missing or empty fields are not accepted.  

**Text Quality:**  
- Both prompt and completion must be text (not empty objects, numbers, or binary).  
- Must not contain invalid characters or tokens.  

**Sample Length:**  
- Each sample ‚â§ **2048 tokens** (standard).  
- Some models support up to **16k tokens**, but require correct configuration.  
- If exceeded ‚Üí the system will raise an error.  

**Duplication:**  
- The system automatically warns if duplicate samples > **10%**.  
- Users are encouraged to clean duplicates before upload.  

**Balance:**  
- Prompts and completions should be well-distributed, not biased toward a single type of question.  


### 3.3. Advanced Validation (Recommended)
- Check for dataset bias (no harmful or sensitive content).  
- Ensure **UTF-8 encoding** to avoid parsing errors.  

---


## 4. Common Issues & How to Avoid Them
- **Context drift:** Always keep prompt formatting consistent.  
- **Overly long or redundant completions:** Keep only the necessary output.  
- **Noisy data (typos, duplicates):** Clean before uploading.  
- **Oversized files (>100MB):** Split or compress into ZIP.  
- **Exceeding max length (2048 or 16k tokens):** Normalize data before upload.  
